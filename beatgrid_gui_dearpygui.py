#!/usr/bin/env python3
"""
Professional GPU-accelerated beatgrid alignment GUI using Dear PyGui
Provides real-time, 60+ FPS performance for DJ Mix Generator
"""

import numpy as np
import librosa
import sounddevice as sd
import threading
import time
from typing import Optional, Callable, Tuple
from models import Track

try:
    import dearpygui.dearpygui as dpg
    DEARPYGUI_AVAILABLE = True
except ImportError:
    DEARPYGUI_AVAILABLE = False
    print("Dear PyGui not available. Install with: pip install dearpygui>=1.10.0")


class ProfessionalBeatgridAligner:
    """GPU-accelerated 3-step beatgrid alignment with real-time performance"""
    
    def __init__(self, track1: Track, track2: Track, track1_outro: np.ndarray, track2_intro: np.ndarray,
                 outro_start: int, track2_start_sample: int, transition_duration: float):
        
        if not DEARPYGUI_AVAILABLE:
            raise ImportError("Dear PyGui is required for the professional beatgrid aligner")
        
        # Track data
        self.track1 = track1
        self.track2 = track2
        self.track1_outro = track1_outro
        self.track2_intro = track2_intro
        self.outro_start = outro_start
        self.track2_start_sample = track2_start_sample
        self.transition_duration = transition_duration
        
        # Display parameters - show 4 measures for clarity
        self.beats_per_measure = 4
        self.measures_to_show = 4
        beats_per_second = track1.bpm / 60.0
        self.display_duration = (self.measures_to_show * self.beats_per_measure) / beats_per_second
        self.display_duration = min(self.display_duration, transition_duration)
        self.sr = track1.sr
        
        # Calculate display audio segments and time axis
        display_samples = int(self.display_duration * self.sr)
        self.track1_display = track1_outro[:display_samples] if len(track1_outro) >= display_samples else track1_outro
        self.track2_display = track2_intro[:display_samples] if len(track2_intro) >= display_samples else track2_intro
        
        # Create time axis in measures
        time_seconds = np.linspace(0, len(self.track1_display) / self.sr, len(self.track1_display))
        beats_per_second = track1.bpm / 60.0
        measures_per_second = beats_per_second / self.beats_per_measure
        self.time_axis = time_seconds * measures_per_second
        
        # Workflow state
        self.current_step = 1  # 1=Track 1, 2=Track 2, 3=Final alignment
        self.track1_adjusted_downbeat = None
        self.track2_adjusted_downbeat = None
        
        # Track adjustments
        self.track1_offset = 0.0  # Time offset in seconds
        self.track2_offset = 0.0
        self.track1_bpm_adjustment = 1.0  # BPM multiplier
        self.track2_bpm_adjustment = 1.0
        
        # Audio playback state
        self.is_playing = False
        self.playback_position = 0.0
        self.playback_start_time = None
        self.playback_thread = None
        self.stop_playback_flag = False
        
        # Stretching state
        self.stretching = False
        self.stretch_anchor_measure = None
        self.original_bpm = None
        
        # Callback for result
        self.callback_func = None
        self.result_offset = 0.0
        
        # GUI state
        self.gui_running = False
        
    def create_gui(self):
        """Create the professional GPU-accelerated beatgrid alignment interface"""
        dpg.create_context()
        
        # Create professional dark theme
        self._setup_theme()
        
        # Create main window
        with dpg.window(label="Professional Beatgrid Alignment", 
                       width=1400, height=900, tag="main_window"):
            
            # Step indicator
            self.step_indicator = dpg.add_text("STEP 1: Adjust Track 1 Beatgrid", 
                                             color=(100, 200, 255))
            
            # Instructions panel
            with dpg.collapsing_header(label="üìã Instructions", default_open=True):
                self.instruction_text = dpg.add_text(self._get_step_instructions(), 
                                                   wrap=1350)
            
            dpg.add_separator()
            
            # Main waveform visualization area
            self._create_waveform_plots()
            
            dpg.add_separator()
            
            # Control panel
            self._create_control_panel()
            
            dpg.add_separator()
            
            # Status and progress
            with dpg.group(horizontal=True):
                self.status_text = dpg.add_text("Ready - Adjust the beatgrid and click Play to test", 
                                               color=(150, 255, 150))
                dpg.add_same_line(spacing=50)
                self.alignment_quality = dpg.add_text("Alignment: Not measured", 
                                                     color=(255, 255, 150))
        
        # Setup viewport
        dpg.create_viewport(title="üéµ Professional DJ Mix Generator - Beatgrid Alignment", 
                          width=1450, height=950)
        
        # Apply theme and setup
        dpg.bind_theme(self.global_theme)
        dpg.setup_dearpygui()
        
        return True
    
    def _setup_theme(self):
        """Create professional dark theme for audio application"""
        with dpg.theme() as self.global_theme:
            with dpg.theme_component(dpg.mvAll):
                # Dark professional color scheme
                dpg.add_theme_color(dpg.mvThemeCol_WindowBg, (25, 25, 30))
                dpg.add_theme_color(dpg.mvThemeCol_ChildBg, (20, 20, 25))
                dpg.add_theme_color(dpg.mvThemeCol_PopupBg, (35, 35, 40))
                dpg.add_theme_color(dpg.mvThemeCol_FrameBg, (45, 45, 50))
                dpg.add_theme_color(dpg.mvThemeCol_FrameBgHovered, (55, 55, 65))
                dpg.add_theme_color(dpg.mvThemeCol_FrameBgActive, (65, 65, 75))
                dpg.add_theme_color(dpg.mvThemeCol_TitleBg, (35, 35, 40))
                dpg.add_theme_color(dpg.mvThemeCol_TitleBgActive, (45, 45, 50))
                dpg.add_theme_color(dpg.mvThemeCol_Button, (50, 130, 200))
                dpg.add_theme_color(dpg.mvThemeCol_ButtonHovered, (70, 150, 220))
                dpg.add_theme_color(dpg.mvThemeCol_ButtonActive, (40, 110, 180))
                dpg.add_theme_color(dpg.mvThemeCol_Header, (50, 50, 60))
                dpg.add_theme_color(dpg.mvThemeCol_HeaderHovered, (60, 60, 75))
                dpg.add_theme_color(dpg.mvThemeCol_HeaderActive, (70, 70, 85))
                
                # Professional styling
                dpg.add_theme_style(dpg.mvStyleVar_FrameRounding, 6)
                dpg.add_theme_style(dpg.mvStyleVar_WindowRounding, 8)
                dpg.add_theme_style(dpg.mvStyleVar_ChildRounding, 6)
                dpg.add_theme_style(dpg.mvStyleVar_PopupRounding, 6)
                dpg.add_theme_style(dpg.mvStyleVar_ScrollbarRounding, 6)
                dpg.add_theme_style(dpg.mvStyleVar_GrabRounding, 6)
                dpg.add_theme_style(dpg.mvStyleVar_WindowPadding, 12, 12)
                dpg.add_theme_style(dpg.mvStyleVar_FramePadding, 8, 6)
                dpg.add_theme_style(dpg.mvStyleVar_ItemSpacing, 8, 6)
    
    def _create_waveform_plots(self):
        """Create GPU-accelerated waveform visualization"""
        if self.current_step in [1, 2]:
            # Single track view
            self._create_single_track_plot()
        else:
            # Dual track view
            self._create_dual_track_plots()
    
    def _create_single_track_plot(self):
        """Create single track waveform plot for steps 1 and 2"""
        track = self.track1 if self.current_step == 1 else self.track2
        audio_data = self.track1_display if self.current_step == 1 else self.track2_display
        color = (100, 150, 255) if self.current_step == 1 else (255, 150, 100)
        
        with dpg.plot(label=f"Track {self.current_step} Waveform Analysis", 
                     height=350, width=1350, tag="main_plot"):
            
            # Configure axes
            x_axis = dpg.add_plot_axis(dpg.mvXAxis, label="Measures", tag="x_axis")
            dpg.set_axis_limits("x_axis", 0, self.measures_to_show)
            
            y_axis = dpg.add_plot_axis(dpg.mvYAxis, label="Amplitude", tag="y_axis")
            dpg.set_axis_limits("y_axis", -1.1, 1.1)
            
            # Waveform visualization (GPU-accelerated)
            dpg.add_line_series(self.time_axis.tolist(), audio_data.tolist(), 
                               label="Waveform", parent="y_axis", tag="waveform")
            
            # Beat lines will be added dynamically
            self.beat_lines_tag = "beat_lines"
            self.downbeat_lines_tag = "downbeat_lines"
            self.playback_line_tag = "playback_line"
            
        # Add drag and drop handler for beatgrid manipulation
        with dpg.drag_payload(parent="main_plot", drag_data="beatgrid"):
            dpg.add_text("Adjusting Beatgrid")
    
    def _create_dual_track_plots(self):
        """Create dual track view for step 3"""
        # Track 1 plot
        with dpg.plot(label="Track 1 (Reference)", height=175, width=1350, tag="plot1"):
            x_axis1 = dpg.add_plot_axis(dpg.mvXAxis, label="", tag="x_axis1")
            dpg.set_axis_limits("x_axis1", 0, self.measures_to_show)
            y_axis1 = dpg.add_plot_axis(dpg.mvYAxis, label="", tag="y_axis1")
            dpg.set_axis_limits("y_axis1", -1.1, 1.1)
            
            dpg.add_line_series(self.time_axis.tolist(), self.track1_display.tolist(),
                               label="Track 1", parent="y_axis1", tag="waveform1")
        
        # Track 2 plot
        with dpg.plot(label="Track 2 (Incoming)", height=175, width=1350, tag="plot2"):
            x_axis2 = dpg.add_plot_axis(dpg.mvXAxis, label="Measures", tag="x_axis2")
            dpg.set_axis_limits("x_axis2", 0, self.measures_to_show)
            y_axis2 = dpg.add_plot_axis(dpg.mvYAxis, label="", tag="y_axis2")
            dpg.set_axis_limits("y_axis2", -1.1, 1.1)
            
            dpg.add_line_series(self.time_axis.tolist(), self.track2_display.tolist(),
                               label="Track 2", parent="y_axis2", tag="waveform2")
        
        self.beat_lines_tag = "beat_lines_dual"
        self.downbeat_lines_tag = "downbeat_lines_dual"
        self.playback_line_tag = "playback_line_dual"
    
    def _create_control_panel(self):
        """Create professional control panel"""
        with dpg.group(horizontal=True):
            # Play controls
            with dpg.child_window(width=300, height=120, border=True):
                dpg.add_text("üéµ Playback Controls", color=(150, 255, 150))
                self.play_button = dpg.add_button(label="‚ñ∂Ô∏è Play Section", 
                                                callback=self._toggle_playback,
                                                width=120, height=35)
                
                # Volume control
                dpg.add_slider_float(label="Volume", default_value=0.8, 
                                   min_value=0.0, max_value=1.0,
                                   callback=self._update_volume,
                                   width=120)
            
            # BPM and stretch controls  
            with dpg.child_window(width=350, height=120, border=True):
                dpg.add_text("üéõÔ∏è Tempo Controls", color=(255, 200, 100))
                
                current_bpm = self.track1.bpm if self.current_step == 1 else self.track2.bpm
                self.bpm_slider = dpg.add_slider_float(label="BPM", 
                                                     default_value=current_bpm,
                                                     min_value=current_bpm * 0.5,
                                                     max_value=current_bpm * 2.0,
                                                     callback=self._update_bpm_live,
                                                     format="%.1f",
                                                     width=150)
                
                with dpg.group(horizontal=True):
                    dpg.add_button(label="üéØ Auto-Align", callback=self._auto_align,
                                 width=80, height=30)
                    dpg.add_button(label="‚Üª Reset", callback=self._reset_alignment, 
                                 width=60, height=30)
            
            # Step navigation
            with dpg.child_window(width=250, height=120, border=True):
                dpg.add_text("üìã Workflow", color=(255, 150, 255))
                
                if self.current_step < 3:
                    dpg.add_button(label="‚û°Ô∏è Next Step", callback=self._next_step,
                                 width=100, height=40)
                else:
                    dpg.add_button(label="‚úÖ Confirm", callback=self._confirm_alignment,
                                 width=100, height=40)
                
                dpg.add_button(label="‚ùå Cancel", callback=self._cancel_alignment,
                             width=100, height=30)
            
            # Alignment info
            with dpg.child_window(width=400, height=120, border=True):
                dpg.add_text("üìä Alignment Status", color=(200, 200, 255))
                self.offset_display = dpg.add_text("Offset: 0.000s")
                self.bpm_display = dpg.add_text(f"BPM: {current_bpm:.1f}")
                self.quality_display = dpg.add_text("Quality: Not measured")
    
    def _get_step_instructions(self):
        """Get instructions for current step"""
        if self.current_step == 1:
            return (
                "STEP 1: Adjust Track 1 Beatgrid\n"
                "‚Ä¢ Use BPM slider to stretch/contract the beatgrid tempo\n" 
                "‚Ä¢ Click and drag in the waveform to shift beat alignment\n"
                "‚Ä¢ Use Play button to hear the audio with live position indicator\n"
                "‚Ä¢ Purple lines = downbeats (most important for transitions)\n"
                "‚Ä¢ Blue lines = regular beats\n"
                "‚Ä¢ Click 'Next Step' when perfectly aligned"
            )
        elif self.current_step == 2:
            return (
                "STEP 2: Adjust Track 2 Beatgrid\n"
                "‚Ä¢ Use BPM slider to stretch/contract the beatgrid tempo\n"
                "‚Ä¢ Click and drag in the waveform to shift beat alignment\n" 
                "‚Ä¢ Use Play button to hear the audio with live position indicator\n"
                "‚Ä¢ Green lines = downbeats (most important for transitions)\n"
                "‚Ä¢ Orange lines = regular beats\n"
                "‚Ä¢ Click 'Next Step' when perfectly aligned"
            )
        else:
            return (
                "STEP 3: Final Transition Alignment\n"
                "‚Ä¢ Both tracks are shown with their adjusted beatgrids\n"
                "‚Ä¢ Purple lines (Track 1) and Green lines (Track 2) show transition points\n"
                "‚Ä¢ Fine-tune using the controls if needed\n"
                "‚Ä¢ Click 'Confirm' to create the final aligned transition"
            )
    
    def _toggle_playback(self):
        """Toggle audio playback with immediate visual feedback"""
        if self.is_playing:
            self._stop_playback()
        else:
            self._start_playback()
    
    def _start_playback(self):
        """Start audio playback with GPU-accelerated position indicator"""
        try:
            # Get current track audio
            if self.current_step == 1:
                audio_data = self.track1_display.copy()
                sr = self.track1.sr
                track_name = "Track 1"
            else:
                audio_data = self.track2_display.copy()
                sr = self.track2.sr
                track_name = "Track 2"
            
            # Prepare audio (mono, normalized)
            if len(audio_data.shape) > 1:
                audio_data = np.mean(audio_data, axis=1)
            audio_data = audio_data.astype(np.float32)
            
            # Normalize to prevent crackling
            max_val = np.max(np.abs(audio_data))
            if max_val > 0:
                audio_data = audio_data * 0.9 / max_val
            
            # Start from current position
            start_sample = int(self.playback_position * sr)
            if start_sample >= len(audio_data):
                self.playback_position = 0.0
                start_sample = 0
            
            audio_to_play = audio_data[start_sample:]
            
            # Update state
            self.is_playing = True
            self.stop_playback_flag = False
            self.playback_start_time = time.time()
            
            # Update button
            dpg.set_item_label(self.play_button, "‚è∏Ô∏è Pause")
            dpg.set_value(self.status_text, f"‚ñ∂Ô∏è Playing {track_name}")
            
            # Start audio
            sd.play(audio_to_play, samplerate=sr)
            
            # Start visual indicator thread (60 FPS)
            self.playback_thread = threading.Thread(target=self._update_playback_indicator)
            self.playback_thread.daemon = True
            self.playback_thread.start()
            
        except Exception as e:
            print(f"Playback failed: {e}")
            self._reset_playback_ui()
    
    def _stop_playback(self):
        """Stop audio playback and save position"""
        try:
            # Calculate final position
            if self.is_playing and self.playback_start_time:
                elapsed = time.time() - self.playback_start_time
                sr = self.track1.sr if self.current_step == 1 else self.track2.sr
                audio_length = len(self.track1_display if self.current_step == 1 else self.track2_display)
                max_duration = audio_length / sr
                
                self.playback_position = min(
                    self.playback_position + elapsed,
                    max_duration
                )
            
            # Stop audio and threading
            self.stop_playback_flag = True
            self.is_playing = False
            sd.stop()
            
            # Update UI
            self._reset_playback_ui()
            
        except Exception as e:
            print(f"Error stopping playback: {e}")
            self._reset_playback_ui()
    
    def _reset_playback_ui(self):
        """Reset playback UI elements"""
        try:
            dpg.set_item_label(self.play_button, "‚ñ∂Ô∏è Play Section")
            dpg.set_value(self.status_text, f"‚è∏Ô∏è Paused at {self.playback_position:.1f}s")
        except:
            pass
    
    def _update_playback_indicator(self):
        """GPU-accelerated 60 FPS playback position updates"""
        while self.is_playing and not self.stop_playback_flag:
            try:
                # Calculate position
                elapsed = time.time() - self.playback_start_time
                sr = self.track1.sr if self.current_step == 1 else self.track2.sr
                audio_length = len(self.track1_display if self.current_step == 1 else self.track2_display)
                max_duration = audio_length / sr
                
                current_position = self.playback_position + elapsed
                
                if current_position >= max_duration:
                    # Playback finished
                    self.is_playing = False
                    self.playback_position = 0.0
                    self._reset_playback_ui()
                    break
                
                # Convert to measures for display
                current_bpm = self._get_current_bpm()
                beats_per_second = current_bpm / 60.0
                measures_per_second = beats_per_second / self.beats_per_measure
                playback_measure = current_position * measures_per_second
                
                # Update playback line (GPU-accelerated)
                if 0 <= playback_measure <= self.measures_to_show:
                    # This would update the playback indicator line
                    # Implementation depends on how we draw the beatgrid lines
                    pass
                
                time.sleep(1/60)  # 60 FPS updates
                
            except Exception as e:
                print(f"Playback indicator error: {e}")
                break
    
    def _get_current_bpm(self):
        """Get current BPM based on adjustments"""
        if self.current_step == 1:
            return self.track1.bpm * self.track1_bpm_adjustment
        else:
            return self.track2.bpm * self.track2_bpm_adjustment
    
    def _update_volume(self, sender, value):
        """Update playback volume"""
        # Volume control implementation
        pass
    
    def _update_bpm_live(self, sender, value):
        """Real-time BPM updates with immediate visual feedback"""
        if self.current_step == 1:
            self.track1_bpm_adjustment = value / self.track1.bpm
        else:
            self.track2_bpm_adjustment = value / self.track2.bpm
        
        # Update display
        dpg.set_value(self.bpm_display, f"BPM: {value:.1f}")
        dpg.set_value(self.status_text, f"üéõÔ∏è BPM adjusted to {value:.1f}")
        
        # Update beatgrid visualization immediately
        self._update_beatgrid_display()
    
    def _update_beatgrid_display(self):
        """Update beatgrid lines with GPU acceleration"""
        # This will be implemented to update the beat line positions
        # based on current BPM and offset adjustments
        pass
    
    def _auto_align(self):
        """Automatically find optimal alignment"""
        dpg.set_value(self.status_text, "ü§ñ Auto-aligning beats...")
        # Implementation for automatic beat alignment
        pass
    
    def _reset_alignment(self):
        """Reset all adjustments to original values"""
        if self.current_step == 1:
            self.track1_offset = 0.0
            self.track1_bpm_adjustment = 1.0
            dpg.set_value(self.bpm_slider, self.track1.bpm)
        else:
            self.track2_offset = 0.0
            self.track2_bpm_adjustment = 1.0
            dpg.set_value(self.bpm_slider, self.track2.bpm)
        
        self._update_beatgrid_display()
        dpg.set_value(self.status_text, "‚Üª Alignment reset to original")
    
    def _next_step(self):
        """Advance to next step in workflow"""
        if self.current_step == 1:
            # Save Track 1 adjustments
            self.track1_adjusted_downbeat = self._get_current_downbeat_position()
            self.current_step = 2
            self._refresh_ui_for_step()
        elif self.current_step == 2:
            # Save Track 2 adjustments  
            self.track2_adjusted_downbeat = self._get_current_downbeat_position()
            self.current_step = 3
            self._refresh_ui_for_step()
    
    def _get_current_downbeat_position(self):
        """Calculate current first downbeat position"""
        # Implementation to find the current first downbeat position
        # based on user adjustments
        return 0.0  # Placeholder
    
    def _refresh_ui_for_step(self):
        """Refresh UI for current workflow step"""
        # Update step indicator
        step_text = f"STEP {self.current_step}: "
        if self.current_step == 1:
            step_text += "Adjust Track 1 Beatgrid"
        elif self.current_step == 2:
            step_text += "Adjust Track 2 Beatgrid"
        else:
            step_text += "Final Alignment"
        
        dpg.set_value(self.step_indicator, step_text)
        dpg.set_value(self.instruction_text, self._get_step_instructions())
        
        # This would recreate the plots for the new step
        # For now, we'll just update the display
        current_bpm = self.track1.bpm if self.current_step == 1 else self.track2.bpm
        dpg.set_value(self.bmp_slider, current_bpm)
        dpg.set_value(self.bpm_display, f"BPM: {current_bmp:.1f}")
    
    def _confirm_alignment(self):
        """Confirm final alignment and return result"""
        # Calculate final offset result
        self.result_offset = self.track2_offset
        
        dpg.set_value(self.status_text, "‚úÖ Alignment confirmed!")
        
        # Close GUI and return result
        self._close_with_result(self.result_offset)
    
    def _cancel_alignment(self):
        """Cancel alignment and return original values"""
        dpg.set_value(self.status_text, "‚ùå Alignment cancelled")
        self._close_with_result(0.0)
    
    def _close_with_result(self, offset: float):
        """Close GUI and return result via callback"""
        # Stop any playback
        if self.is_playing:
            self._stop_playback()
        
        time.sleep(0.1)  # Brief cleanup delay
        
        self.gui_running = False
        if self.callback_func:
            self.callback_func(offset)
        
        dpg.destroy_context()
    
    def show(self, callback_func: Optional[Callable] = None) -> Optional[float]:
        """Show the professional beatgrid alignment GUI"""
        self.callback_func = callback_func
        
        if not self.create_gui():
            return 0.0
        
        dpg.show_viewport()
        self.gui_running = True
        
        # Main GUI loop
        while dpg.is_dearpygui_running() and self.gui_running:
            dpg.render_dearpygui_frame()
        
        return None


def align_beatgrids_interactive(track1: Track, track2: Track, track1_outro: np.ndarray, track2_intro: np.ndarray,
                               outro_start: int, track2_start_sample: int, transition_duration: float) -> float:
    """
    Professional GPU-accelerated interactive beatgrid alignment
    
    Returns:
        Time offset in seconds for perfect track alignment
    """
    if not DEARPYGUI_AVAILABLE:
        print("Dear PyGui not available - falling back to automatic alignment")
        return 0.0
    
    try:
        aligner = ProfessionalBeatgridAligner(
            track1, track2, track1_outro, track2_intro,
            outro_start, track2_start_sample, transition_duration
        )
        
        # Result container for callback
        result_container = {'result': 0.0}
        
        def capture_result(result):
            result_container['result'] = result
        
        print("üéµ Opening professional beatgrid aligner...")
        print("GPU-accelerated interface with real-time feedback")
        
        aligner.show(callback_func=capture_result)
        return result_container['result']
        
    except Exception as e:
        print(f"Professional beatgrid aligner failed: {e}")
        print("Falling back to automatic alignment")
        return 0.0


if __name__ == "__main__":
    if DEARPYGUI_AVAILABLE:
        print("‚úÖ Dear PyGui Professional Beatgrid Aligner Ready")
        print("Run the main DJ mix generator with --interactive-beats to use")
    else:
        print("‚ùå Dear PyGui not available")
        print("Install with: pip install dearpygui>=1.10.0")